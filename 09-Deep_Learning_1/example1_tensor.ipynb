{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tutorial - example1\n",
    "MILA, November 2017 created by Sandeep Subramanian, <br>\n",
    "modified by Sam,Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Getting Started\n",
    "---------------\n",
    "\n",
    "Tensors are similar to NumPyâ€™s ndarrays, with the addition being that\n",
    "Tensors can also be used on a GPU to accelerate computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to the torch tensor library\n",
    "### Torch's numpy equivalent with GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a random tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.8784e-37, 0.0000e+00, 5.7453e-44],\n",
       "        [0.0000e+00,        nan, 0.0000e+00],\n",
       "        [1.3733e-14, 6.4076e+07, 2.0706e-19],\n",
       "        [7.3909e+22, 2.4176e-12, 1.1625e+33],\n",
       "        [8.9605e-01, 1.1632e+33, 5.6003e-02]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3436, -0.7953,  0.4060],\n",
       "        [-0.2703, -0.2129,  0.9883],\n",
       "        [-0.1596,  0.7189, -0.3340],\n",
       "        [ 0.6688, -0.2721, -0.4651],\n",
       "        [-0.9866,  0.7773, -0.6973]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(5, 3).uniform_(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get it's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5, 3).uniform_(-1, 1)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Types\n",
    "source: http://pytorch.org/docs/master/tensors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Data type |CPU Tensor| \n",
    "|----------|------|\n",
    "|32-bit floating point\t\t|torch.FloatTensor\t|\n",
    "|64-bit floating point\t\t|torch.DoubleTensor\t|\n",
    "|16-bit floating point\t\t|torch.HalfTensor\t|\n",
    "|8-bit integer (unsigned)\t|torch.ByteTensor\t| \n",
    "|8-bit integer (signed)\t\t|torch.CharTensor\t|\n",
    "|16-bit integer (signed)\t|torch.ShortTensor\t|\n",
    "|32-bit integer (signed)\t|torch.IntTensor\t|\n",
    "|64-bit integer (signed)\t|torch.LongTensor\t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation from lists & numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "z_list = [[1, 3], [2, 9]]\n",
    "z_tensor = torch.LongTensor(z_list)\n",
    "\n",
    "print(z_tensor.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.DoubleTensor\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Data type inferred from numpy\n",
    "print(torch.from_numpy(np.random.rand(5, 3)).type())\n",
    "print(torch.from_numpy(np.random.rand(5, 3).astype(np.float32)).type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9584,  0.2909,  0.1692],\n",
      "        [-0.3198, -0.1206,  0.1645],\n",
      "        [-0.1721,  0.0272,  0.6707],\n",
      "        [-0.2575, -0.0220,  0.0174],\n",
      "        [ 0.1110, -0.0053, -0.2779]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5, 3).uniform_(-1, 1)\n",
    "y = x * torch.randn(5, 3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-28.8388,   0.3105,   0.4103],\n",
      "        [  0.6236,   0.6080,   1.4383],\n",
      "        [ -0.5634, -22.8925,  -3.5114],\n",
      "        [ -0.6186,   0.0277,  -0.0335],\n",
      "        [ -0.2014,  -0.0063,   0.2169]])\n"
     ]
    }
   ],
   "source": [
    "y = x / torch.sqrt(torch.randn(5, 3) ** 2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "tensor([[-1.7199, -0.6759, -0.9883],\n",
      "        [ 1.6619,  1.7797,  1.8658],\n",
      "        [ 0.3984,  0.3549,  0.1488],\n",
      "        [ 0.4315,  0.6279,  0.5965],\n",
      "        [ 1.1481,  1.2040,  1.4294]])\n"
     ]
    }
   ],
   "source": [
    "print (x.size())\n",
    "y = x + torch.randn(5, 1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 15])\n",
      "torch.Size([50, 15])\n",
      "torch.Size([50, 1, 15])\n",
      "torch.Size([50, 15])\n",
      "\n",
      "torch.Size([10, 5, 15])\n",
      "torch.Size([5, 15, 10])\n",
      "torch.Size([10, 15, 5])\n",
      "torch.Size([10, 15, 5])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randn(5, 10, 15)\n",
    "print(y.size())\n",
    "print(y.view(-1, 15).size())  # Same as doing y.view(50, 15)\n",
    "print(y.view(-1, 15).unsqueeze(1).size()) # Adds a dimension at index 1.\n",
    "print(y.view(-1, 15).unsqueeze(1).squeeze().size())\n",
    "# If input is of shape: (Ax1xBxCx1xD)(Ax1xBxCx1xD) then the out Tensor will be of shape: (AxBxCxD)(AxBxCxD)\n",
    "print()\n",
    "print(y.transpose(0, 1).size())\n",
    "print(y.transpose(1, 2).size())\n",
    "print(y.transpose(0, 1).transpose(1, 2).size())\n",
    "print(y.permute(1, 2, 0).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 100, 15])\n",
      "torch.Size([50, 100, 15])\n"
     ]
    }
   ],
   "source": [
    "print(y.view(-1, 15).unsqueeze(1).expand(50, 100, 15).size())\n",
    "print(y.view(-1, 15).unsqueeze(1).expand_as(torch.randn(50, 100, 15)).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4464, 1.4904, 1.1780],\n",
      "        [1.4012, 1.5190, 1.6051],\n",
      "        [0.6165, 0.5730, 0.3669],\n",
      "        [0.8199, 1.0162, 0.9848],\n",
      "        [0.9378, 0.9938, 1.2192]], device='cuda:0')\n",
      "tensor([[0.4464, 1.4904, 1.1780],\n",
      "        [1.4012, 1.5190, 1.6051],\n",
      "        [0.6165, 0.5730, 0.3669],\n",
      "        [0.8199, 1.0162, 0.9848],\n",
      "        [0.9378, 0.9938, 1.2192]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move tensors on the CPU -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6363, -0.2772, -0.9638],\n",
      "        [ 0.9925, -0.6542, -0.9112],\n",
      "        [ 0.8720, -0.8898, -0.8583],\n",
      "        [ 0.5808, -0.7167, -0.5268],\n",
      "        [-0.9483,  0.4500,  0.3293]])\n",
      "tensor([[-0.6363, -0.2772, -0.9638],\n",
      "        [ 0.9925, -0.6542, -0.9112],\n",
      "        [ 0.8720, -0.8898, -0.8583],\n",
      "        [ 0.5808, -0.7167, -0.5268],\n",
      "        [-0.9483,  0.4500,  0.3293]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(5, 3).uniform_(-1, 1)\n",
    "print(x)\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda(device=0)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy and torch.Tensor comparison\n",
    "### Type\n",
    "\n",
    "<table align='left'>\n",
    "<thead>\n",
    "<tr><th>Numpy                  </th><th>PyTorch                                 </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td><code>np.ndarray</code></td><td><code>torch.Tensor</code>               </td></tr>\n",
    "<tr><td><code>np.float32</code></td><td><code>torch.float32; torch.float</code> </td></tr>\n",
    "<tr><td><code>np.float64</code></td><td><code>torch.float64; torch.double</code></td></tr>\n",
    "<tr><td><code>np.float16</code></td><td><code>torch.float16; torch.half</code>  </td></tr>\n",
    "<tr><td><code>np.int8</code>   </td><td><code>torch.int8</code>                 </td></tr>\n",
    "<tr><td><code>np.uint8</code>  </td><td><code>torch.uint8</code>                </td></tr>\n",
    "<tr><td><code>np.int16</code>  </td><td><code>torch.int16; torch.short</code>   </td></tr>\n",
    "<tr><td><code>np.int32</code>  </td><td><code>torch.int32; torch.int</code>     </td></tr>\n",
    "<tr><td><code>np.int64</code>  </td><td><code>torch.int64; torch.long</code>    </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical ranges\n",
    "\n",
    "<table align='left'>\n",
    "<thead>\n",
    "<tr><th>Numpy                            </th><th>PyTorch                             </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td><code>np.arange(10)</code>       </td><td><code>torch.arange(10)</code>       </td></tr>\n",
    "<tr><td><code>np.arange(2, 3, 0.1)</code></td><td><code>torch.arange(2, 3, 0.1)</code></td></tr>\n",
    "<tr><td><code>np.linspace</code>         </td><td><code>torch.linspace</code>         </td></tr>\n",
    "<tr><td><code>np.logspace</code>         </td><td><code>torch.logspace</code>         </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes\n",
    "\n",
    "<table align='left'>\n",
    "<thead>\n",
    "<tr><th>Numpy                 </th><th>PyTorch                  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td><code>x.shape</code>  </td><td><code>x.shape</code>     </td></tr>\n",
    "<tr><td><code>x.strides</code></td><td><code>x.stride()</code>  </td></tr>\n",
    "<tr><td><code>x.ndim</code>   </td><td><code>x.dim()</code>     </td></tr>\n",
    "<tr><td><code>x.data</code>   </td><td><code>x.data</code>      </td></tr>\n",
    "<tr><td><code>x.size</code>   </td><td><code>x.nelement()</code></td></tr>\n",
    "<tr><td><code>x.dtype</code>  </td><td><code>x.dtype</code>     </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation\n",
    "<table align='left'>\n",
    "<thead>\n",
    "<tr><th>Numpy                   </th><th>PyTorch                                    </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td><code>x.min</code>      </td><td><code>x.min</code>                         </td></tr>\n",
    "<tr><td><code>x.argmin</code>   </td><td><code>x.argmin</code>                      </td></tr>\n",
    "<tr><td><code>x.max</code>      </td><td><code>x.max</code>                         </td></tr>\n",
    "<tr><td><code>x.argmax</code>   </td><td><code>x.argmax</code>                      </td></tr>\n",
    "<tr><td><code>x.clip</code>     </td><td><code>x.clamp</code>                       </td></tr>\n",
    "<tr><td><code>x.round</code>    </td><td><code>x.round</code>                       </td></tr>\n",
    "<tr><td><code>np.floor(x)</code></td><td><code>torch.floor(x); x.floor()</code>     </td></tr>\n",
    "<tr><td><code>np.ceil(x)</code> </td><td><code>torch.ceil(x); x.ceil()</code>       </td></tr>\n",
    "<tr><td><code>x.trace</code>    </td><td><code>x.trace</code>                       </td></tr>\n",
    "<tr><td><code>x.sum</code>      </td><td><code>x.sum</code>                         </td></tr>\n",
    "<tr><td><code>x.cumsum</code>   </td><td><code>x.cumsum</code>                      </td></tr>\n",
    "<tr><td><code>x.mean</code>     </td><td><code>x.mean</code>                        </td></tr>\n",
    "<tr><td><code>x.std</code>      </td><td><code>x.std</code>                         </td></tr>\n",
    "<tr><td><code>x.prod</code>     </td><td><code>x.prod</code>                        </td></tr>\n",
    "<tr><td><code>x.cumprod</code>  </td><td><code>x.cumprod</code>                     </td></tr>\n",
    "<tr><td><code>x.all</code>      </td><td><code>(x == 1).sum() == x.nelement()</code></td></tr>\n",
    "<tr><td><code>x.any</code>      </td><td><code>(x == 1).sum() > 0</code>            </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
